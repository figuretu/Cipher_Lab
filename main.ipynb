{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这次解密中 我将综合尝试使用字母频率分析和单词分析法 进行对单字母密码的解密"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先建立一个映射表，存储密钥的映射关系，以及对应的设置函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "def set_dict(keys, values):\n",
    "    for i in range(len(keys)):\n",
    "        dict[keys[i]] = values[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 词频分析 \n",
    "\n",
    "![jupyter](image.png)\n",
    "\n",
    "由图可知e出现次数最高,我们尝试对密文进行词频分析,找到出现次数最高的字母."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('x', 148), ('i', 109), ('j', 90), ('f', 89), ('p', 80), ('b', 79), ('w', 79), ('c', 67), ('s', 55), ('e', 49), ('v', 43), ('y', 40), ('q', 39), ('a', 38), ('m', 32), ('l', 28), ('o', 21), ('r', 20), ('z', 16), ('h', 11), ('g', 10), ('d', 6), ('k', 3), ('t', 2), ('u', 1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#大写转为小写\n",
    "def convert_to_lower_case(string):\n",
    "    return string.lower()\n",
    "\n",
    "#是否为字母构成的字符串\n",
    "def is_alpha(string):\n",
    "    string = convert_to_lower_case(string)\n",
    "    for i in range(len(string)):\n",
    "        if string[i] not in 'abcdefghijklmnopqrstuvwxyz':\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "#打开ciphertext.txt文件\n",
    "#分析每个字母的出现次数\n",
    "\n",
    "counter = {}\n",
    "\n",
    "with open('ciphertext.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "    text = convert_to_lower_case(text)\n",
    "    for i in range(len(text)):\n",
    "        if is_alpha(text[i]) == 0:\n",
    "            continue\n",
    "        if text[i] in counter:\n",
    "            counter[text[i]] += 1\n",
    "        else:\n",
    "            counter[text[i]] = 1\n",
    "    counter = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现, x的出现次数最高,我们将x替换为e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dict('x', 'e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单词分析法\n",
    "我们可以根据语言中的一些规律，分析单词来寻找映射关系\n",
    "1. 单个字母一定为a 如果大写并出现在句首即为i\n",
    "2. 三字母单词中出现频率最高的为the\n",
    "3. 常出现的二字母单词为of, to, in, it, is, as, at, so, we, he, by, or, on, do, if, me, my, up, an, go, no, us, am等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据规则1,在密文中找到j单个出现,替换为a\n",
    "set_dict('j', 'a')\n",
    "\n",
    "#根据规则2\n",
    "words_counter = {} #统计每个单词出现的次数\n",
    "with open('ciphertext.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "    text = convert_to_lower_case(text)\n",
    "    #利用正则表达式提取出所有的单词\n",
    "    import re\n",
    "    words = re.findall(r'[a-z]+', text)\n",
    "    #print(words)\n",
    "    \n",
    "    #统计单词出现次数\n",
    "    for word in words:\n",
    "        if word in words_counter:\n",
    "            words_counter[word] += 1\n",
    "        else:\n",
    "            words_counter[word] = 1\n",
    "    words_counter = sorted(words_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "    #print(words_counter)\n",
    "    \n",
    "    the_str = \"\"\n",
    "    #找到长度为三的单词出现频率最高的，替换为the\n",
    "    for word in words_counter:\n",
    "        if len(word[0]) == 3:\n",
    "            the_str = word[0]\n",
    "            break\n",
    "    #print(the_str)\n",
    "    set_dict(the_str, 'the')\n",
    "\n",
    "#print(dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们已经获得了一些映射关系，所以写一个替换函数，将已知的映射关系替换为明文 其余用\\*代替"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt(string):\n",
    "    string = convert_to_lower_case(string)\n",
    "    result = \"\"\n",
    "    for c in string:\n",
    "        if c in dict: #已知\n",
    "            result += dict[c]\n",
    "        else:\n",
    "            result += '*' #未知用*代替\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试分析单词获得更多的映射关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t* 10 if\n",
      "** 4 wc\n",
      "** 3 fz\n",
      "a* 2 jp\n",
      "** 2 qf\n",
      "** 2 wp\n",
      "** 2 rm\n",
      "*t 2 wi\n",
      "*e 2 rx\n",
      "** 1 fp\n",
      "** 1 cf\n"
     ]
    }
   ],
   "source": [
    "#分析对应长度的单词\n",
    "def analysis(length):\n",
    "    for word in words_counter:\n",
    "        if len(word[0]) == length:\n",
    "            print(decrypt(word[0]), word[1], word[0])\n",
    "analysis(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to 10 if\n",
      "i* 4 wc\n",
      "o* 3 fz\n",
      "a* 2 jp\n",
      "*o 2 qf\n",
      "i* 2 wp\n",
      "** 2 rm\n",
      "it 2 wi\n",
      "*e 2 rx\n",
      "o* 1 fp\n",
      "*o 1 cf\n"
     ]
    }
   ],
   "source": [
    "#查常用二长度单词表得到部分映射关系\n",
    "#of, to, in, it, is, as, at, so, we, he, by, or, on, do, if, me, my, up, an, go, no, us, am\n",
    "#wi -> it\n",
    "#if -> to\n",
    "\n",
    "set_dict('wi', 'it')\n",
    "set_dict('if', 'to')\n",
    "\n",
    "analysis(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 12 iex\n",
      "a** 4 jpq\n",
      "a*e 3 jbx\n",
      "**t 3 rli\n",
      "a** 2 jpm\n",
      "a*e 1 jox\n",
      "*as 1 gjc\n",
      "*a* 1 gjb\n",
      "o*t 1 fli\n",
      "its 1 wic\n",
      "o*e 1 fpx\n",
      "*a* 1 ajq\n",
      "{'x': 'e', 'j': 'a', 'i': 't', 'e': 'h', 'w': 'i', 'f': 'o', 'c': 's'}\n"
     ]
    }
   ],
   "source": [
    "#联系 wc(i*) cf(*o) 可知c代表s 为is和so\n",
    "set_dict('wc', 'is')\n",
    "analysis(3)\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较明显的二长度单词已经添加了映射关系，按理来说我们可以接着分析三长度单词。\n",
    "在这里我们全部注释掉，不需要人工一个个找规律，试探能否找到映射关系。\n",
    "因为在后文中提出了一种算法的改进，可以通过对长单词的模糊匹配来获得更多的映射关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找规律 \n",
    "# jbx(a*e) -> are\n",
    "# jox(a*e) -> age\n",
    "# fpx(o*e) -> one\n",
    "# fli(o*t) -> out\n",
    "\n",
    "\n",
    "# set_dict('jbx', 'are')\n",
    "# set_dict('jox', 'age')\n",
    "# set_dict('fpx', 'one')\n",
    "# set_dict('fli', 'out')\n",
    "# analysis(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*ith 3 gwie\n",
      "*o*e 2 vfbx\n",
      "s**h 2 clse\n",
      "**o* 1 zbfv\n",
      "o*** 1 fpym\n",
      "sa*e 1 cjvx\n",
      "*se* 1 lcxq\n",
      "ha*e 1 ejhx\n",
      "ha** 1 ejbq\n",
      "that 1 ieji\n",
      "e*e* 1 xhxp\n",
      "ti*e 1 iwvx\n",
      "tha* 1 iejp\n",
      "*est 1 rxci\n"
     ]
    }
   ],
   "source": [
    "#找规律 \n",
    "# jpq(an*) -> and\n",
    "# rli(*ut) -> but\n",
    "\n",
    "# set_dict('jpq', 'and')\n",
    "# set_dict('rli', 'but')\n",
    "analysis(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在代码的最开始版本 我人工识别出四长度甚至五六七长度的单词，这样的效率太低下，注释掉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these 3 iexcx\n",
      "**ea* 2 rbxjd\n",
      "**io* 1 abwfb\n",
      "state 1 cijix\n",
      "si**e 1 cwpsx\n",
      "*i*st 1 zwbci\n",
      "*o*** 1 gfbyq\n",
      "*a*** 1 sjbbm\n",
      "*ase* 1 rjcxq\n",
      "**o** 1 dpfgp\n",
      "*ea*s 1 vxjpc\n",
      "the*e 1 iexbx\n",
      "e*ist 1 xkwci\n",
      "*o*e* 1 afgxb\n"
     ]
    }
   ],
   "source": [
    "# set_dict('cjvx', 'same')\n",
    "# set_dict('gwie', 'with')\n",
    "# set_dict('xhxp', 'even')\n",
    "# set_dict('ejhx', 'have')\n",
    "# set_dict('clse', 'such')\n",
    "analysis(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se***e 3 cxslbx\n",
      "*o*e** 2 vfqxbp\n",
      "sha*e* 1 cejbxq\n",
      "*ee*e* 1 pxxqxq\n",
      "a**e*t 1 jqhxpi\n",
      "*e*o*e 1 rxsfvx\n",
      "theo** 1 iexfbm\n",
      "a*o*** 1 jbflpq\n",
      "*a*i** 1 vjdwpo\n",
      "s*ste* 1 cmcixv\n",
      "te**e* 1 ixbvxq\n",
      "*aste* 1 zjcixb\n",
      "*a**ot 1 sjppfi\n",
      "**o*e* 1 rbfdxp\n",
      "s*he*es 3 csexvxc\n",
      "*essa*e 1 vxccjox\n",
      "*e*o*e* 1 bxsfhxb\n",
      "the*e** 1 iexbxrm\n",
      "*e*so*s 1 axbcfpc\n",
      "*etho*s 1 vxiefqc\n",
      "*o***e* 1 sfvayxk\n",
      "hea*i** 1 exjhwym\n",
      "s*ie**e 1 cswxpsx\n",
      "i*te*e* 1 wpixoxb\n",
      "*e**i*e 1 bxtlwbx\n",
      "a*a*te* 1 jqjaixq\n",
      "e*a***e 1 xkjvayx\n"
     ]
    }
   ],
   "source": [
    "# set_dict('dpfgp', 'known')\n",
    "# set_dict('gfbyq', 'world')\n",
    "# set_dict('zwbci', 'first')\n",
    "# set_dict('xkwci', 'exist')\n",
    "analysis(6)\n",
    "analysis(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_dict('cmcixv', 'system')\n",
    "# set_dict('axbcfpc', 'reasons')\n",
    "# set_dict('sfvayxk', 'complex')\n",
    "# set_dict('xkjvayx', 'example')\n",
    "# set_dict('bxtlwbx', 'require')\n",
    "# analysis(6)\n",
    "# analysis(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "{'x': 'e', 'j': 'a', 'i': 't', 'e': 'h', 'w': 'i', 'f': 'o', 'c': 's'}\n",
      "i**o**atio*\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(dict)) \n",
    "print(dict) #打印字典\n",
    "print(decrypt('wpzfbvjiwfp')) #information的密文"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上面可见，人力来模糊查找单词的效率低下，而且容易出错。\n",
    "我们可以通过一些算法来寻找映射关系。\n",
    "\n",
    "我们在一长度和二长度单词中，已经找到了部分映射关系：\n",
    "`'x': 'e', 'j': 'a', 'i': 't', 'e': 'h', 'w': 'i', 'f': 'o', 'c': 's'`\n",
    "\n",
    "猜想是否可以用这些进行模糊匹配，不再手工而是用代码实现后续的寻找呢？\n",
    "\n",
    "例如information,根据已经找到的映射关系，不清楚的用\\*代替，可以得到现在decrype的结果：\n",
    "`i**o**atio*`\n",
    "尽管人工识别有一定难度，但是利用正则进行模糊匹配（`\\b`匹配单词边界）`\\bi[a-z][a-z]o[a-z][a-z]atio[a-z]\\b`：\n",
    "在长度确定，再根据已知的部分是可以模糊识别出唯一的单词的。\n",
    "我们就可以用这个单词更新映射表。\n",
    "\n",
    "在这里，单词长度反而成为了一种标识，越长的单词，我们越能确定它的唯一性。与前面的单词分析法略微不同。\n",
    "\n",
    "导入一个三千单词表，这可以确保大多数的单词都能在其中被找到。\n",
    "我们对密文进行分词，然后对每个单词进行模糊匹配，如果能够找到唯一的对应单词，就更新映射表。\n",
    "这样可以大大提高效率。\n",
    "这部分的代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set dict:\n",
      "\tcipher word: gwie\n",
      "\tmatched word: with\n",
      "\tdict length: 8\n",
      "\n",
      "set dict:\n",
      "\tcipher word: wpzfbvjiwfp\n",
      "\tmatched word: information\n",
      "\tdict length: 12\n",
      "\n",
      "set dict:\n",
      "\tcipher word: cxslbx\n",
      "\tmatched word: secure\n",
      "\tdict length: 14\n",
      "\n",
      "set dict:\n",
      "\tcipher word: vfqxbp\n",
      "\tmatched word: modern\n",
      "\tdict length: 15\n",
      "\n",
      "set dict:\n",
      "\tcipher word: sfvalixb\n",
      "\tmatched word: computer\n",
      "\tdict length: 16\n",
      "\n",
      "set dict:\n",
      "\tcipher word: vxccjox\n",
      "\tmatched word: message\n",
      "\tdict length: 17\n",
      "\n",
      "set dict:\n",
      "\tcipher word: ixsepwtlx\n",
      "\tmatched word: technique\n",
      "\tdict length: 18\n",
      "\n",
      "set dict:\n",
      "\tcipher word: bxsfhxb\n",
      "\tmatched word: recover\n",
      "\tdict length: 19\n",
      "\n",
      "set dict:\n",
      "\tcipher word: gfbyq\n",
      "\tmatched word: world\n",
      "\tdict length: 20\n",
      "\n",
      "set dict:\n",
      "\tcipher word: sjbbm\n",
      "\tmatched word: carry\n",
      "\tdict length: 21\n",
      "\n",
      "set dict:\n",
      "\tcipher word: rxsfvx\n",
      "\tmatched word: become\n",
      "\tdict length: 22\n",
      "\n",
      "set dict:\n",
      "\tcipher word: sfvayxk\n",
      "\tmatched word: complex\n",
      "\tdict length: 23\n",
      "\n",
      "set dict:\n",
      "\tcipher word: rbfdxp\n",
      "\tmatched word: broken\n",
      "\tdict length: 24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#正则表达式模糊查找单词\n",
    "def find_in_list(string : str):\n",
    "    string = r'\\b' + string + r'\\b'\n",
    "    string = string.replace('*', '[a-z]')\n",
    "    #print(string)\n",
    "    with open('wordlist.txt', 'r') as f:\n",
    "        text = f.read()\n",
    "        result = re.findall(string, text)\n",
    "        return result\n",
    "# find_in_list(\"compl*x\")\n",
    "\n",
    "#长度大于2的单词，都拿来做匹配\n",
    "lst = []\n",
    "for word in words_counter:\n",
    "    if len(word[0]) <= 2:\n",
    "        continue\n",
    "    lst.append(word[0])\n",
    "#print(lst[:100])\n",
    "\n",
    "#循环尝试匹配，直到字典中的单词全部匹配\n",
    "while True:\n",
    "    isFound = False\n",
    "    for string in lst:\n",
    "        origin = string\n",
    "        string = decrypt(string)\n",
    "        #print('de:', string)\n",
    "        if '*' not in string: #如果没有*，说明已经匹配，跳过\n",
    "            continue\n",
    "        #print(string)\n",
    "        result = find_in_list(string)\n",
    "        if len(result) == 1:\n",
    "            isFound = True\n",
    "            set_dict(origin, result[0])\n",
    "            print('set dict:')\n",
    "            print('\\tcipher word:', origin)\n",
    "            print('\\tmatched word:', result[0])\n",
    "            print('\\tdict length:', len(dict))\n",
    "            print()\n",
    "    if isFound == False:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明文与密钥的映射:\n",
      "明文字母: a  密钥字母: j\n",
      "明文字母: b  密钥字母: r\n",
      "明文字母: c  密钥字母: s\n",
      "明文字母: d  密钥字母: q\n",
      "明文字母: e  密钥字母: x\n",
      "明文字母: f  密钥字母: z\n",
      "明文字母: g  密钥字母: o\n",
      "明文字母: h  密钥字母: e\n",
      "明文字母: i  密钥字母: w\n",
      "明文字母: k  密钥字母: d\n",
      "明文字母: l  密钥字母: y\n",
      "明文字母: m  密钥字母: v\n",
      "明文字母: n  密钥字母: p\n",
      "明文字母: o  密钥字母: f\n",
      "明文字母: p  密钥字母: a\n",
      "明文字母: q  密钥字母: t\n",
      "明文字母: r  密钥字母: b\n",
      "明文字母: s  密钥字母: c\n",
      "明文字母: t  密钥字母: i\n",
      "明文字母: u  密钥字母: l\n",
      "明文字母: v  密钥字母: h\n",
      "明文字母: w  密钥字母: g\n",
      "明文字母: x  密钥字母: k\n",
      "明文字母: y  密钥字母: m\n"
     ]
    }
   ],
   "source": [
    "#最后进行打印输出\n",
    "def decrypt_all(string):\n",
    "    result = \"\"\n",
    "    for c in string:\n",
    "        if c in dict:\n",
    "            result += dict[c]\n",
    "        else:\n",
    "            if c.lower() in dict: #注意大小写\n",
    "                result += dict[c.lower()].upper()\n",
    "            else:\n",
    "                result += c\n",
    "    return result\n",
    "\n",
    "with open('origintext.txt', 'w') as fout:\n",
    "    with open('ciphertext.txt', 'r') as fin:\n",
    "        text = fin.read()\n",
    "        fout.write(decrypt_all(text))\n",
    "\n",
    "#打印映射表\n",
    "print('明文与密钥的映射:')\n",
    "sorted_dict = sorted(dict.items(), key=lambda x: x[1])\n",
    "for item in sorted_dict:\n",
    "    print('明文字母:', item[1], ' 密钥字母:', item[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解密后的文本为：\n",
    "```\n",
    "Cryptography prior to the modern age was effectively synonymous with encryption, the conversion of information from a readable state to apparent nonsense. The originator of an encrypted message shared the decoding technique needed to recover the original information only with intended recipients, thereby precluding unwanted persons to do the same. Since the first World War and the advent of the computer, the methods used to carry out cryptology have become increasingly complex and its application more widespread.\n",
    "\n",
    "Modern cryptography is heavily based on mathematical theory and computer science practice; cryptographic algorithms are designed around computational hardness assumptions, making such algorithms hard to break in practice by any adversary. It is theoretically possible to break such a system, but it is infeasible to do so by any known practical means. These schemes are therefore termed computationally secure; theoretical advances, e.g., improvements in integer factoriuation algorithms, and faster computing technology require these solutions to be continually adapted. There exist information-theoretically secure schemes that provably cannot be broken even with unlimited computing power--an example is the one-time pad--but these schemes are more difficult to implement than the best theoretically breakable but computationally secure mechanisms.\n",
    "```\n",
    "\n",
    "加密文本为：\n",
    "```\n",
    "Sbmaifobjaem abwfb if iex vfqxbp jox gjc xzzxsiwhxym cmpfpmvflc gwie xpsbmaiwfp, iex sfphxbcwfp fz wpzfbvjiwfp zbfv j bxjqjryx cijix if jaajbxpi pfpcxpcx. Iex fbwowpjifb fz jp xpsbmaixq vxccjox cejbxq iex qxsfqwpo ixsepwtlx pxxqxq if bxsfhxb iex fbwowpjy wpzfbvjiwfp fpym gwie wpixpqxq bxswawxpic, iexbxrm abxsylqwpo lpgjpixq axbcfpc if qf iex cjvx. Cwpsx iex zwbci Gfbyq Gjb jpq iex jqhxpi fz iex sfvalixb, iex vxiefqc lcxq if sjbbm fli sbmaifyfom ejhx rxsfvx wpsbxjcwpoym sfvayxk jpq wic jaaywsjiwfp vfbx gwqxcabxjq.\n",
    "\n",
    "Vfqxbp sbmaifobjaem wc exjhwym rjcxq fp vjiexvjiwsjy iexfbm jpq sfvalixb cswxpsx abjsiwsx; sbmaifobjaews jyofbwievc jbx qxcwopxq jbflpq sfvalijiwfpjy ejbqpxcc jcclvaiwfpc, vjdwpo clse jyofbwievc ejbq if rbxjd wp abjsiwsx rm jpm jqhxbcjbm. Wi wc iexfbxiwsjyym afccwryx if rbxjd clse j cmcixv, rli wi wc wpzxjcwryx if qf cf rm jpm dpfgp abjsiwsjy vxjpc. Iexcx csexvxc jbx iexbxzfbx ixbvxq sfvalijiwfpjyym cxslbx; iexfbxiwsjy jqhjpsxc, x.o., wvabfhxvxpic wp wpixoxb zjsifbwujiwfp jyofbwievc, jpq zjcixb sfvaliwpo ixsepfyfom bxtlwbx iexcx cfyliwfpc if rx sfpiwpljyym jqjaixq. Iexbx xkwci wpzfbvjiwfp-iexfbxiwsjyym cxslbx csexvxc ieji abfhjrym sjppfi rx rbfdxp xhxp gwie lpywvwixq sfvaliwpo afgxb--jp xkjvayx wc iex fpx-iwvx ajq--rli iexcx csexvxc jbx vfbx qwzzwslyi if wvayxvxpi iejp iex rxci iexfbxiwsjyym rbxjdjryx rli sfvalijiwfpjyym cxslbx vxsejpwcvc.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbcefe7cc1b5c8a0efe7bce2a8e6d9d317c4b15f360801b153528886b54c3f98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
